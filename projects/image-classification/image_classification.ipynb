{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 2000:\n",
      "Image - Min Value: 19 Max Value: 255\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 7 Name: horse\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff4c9a37a20>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 2000\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return (x - np.min(x))/(np.max(x) - np.min(x))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "Look into LabelBinarizer in the preprocessing module of sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.classes_ = range(0,10)\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    if not hasattr(lb,'classes_'):\n",
    "        lb.fit(x)\n",
    "    \n",
    "    return lb.transform(x)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape = (None,) + image_shape,name = 'x')\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape = (None, n_classes), name = 'y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32,name = 'keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers.\n",
    "\n",
    "** Hint: **\n",
    "\n",
    "When unpacking values as an argument in Python, look into the [unpacking](https://docs.python.org/3/tutorial/controlflow.html#unpacking-argument-lists) operator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x_tensor_shape = x_tensor.get_shape()\n",
    "    weight = tf.Variable(tf.truncated_normal(conv_ksize + (x_tensor_shape[3].value,) + (conv_num_outputs,),\n",
    "                                             stddev=1/np.sqrt(conv_ksize[0] * conv_ksize[0] * x_tensor_shape[3].value)))\n",
    "    bias = tf.Variable(tf.zeros([conv_num_outputs]))\n",
    "    \n",
    "    convnet = tf.nn.conv2d (x_tensor,\n",
    "                 weight,\n",
    "                 strides = (1,) + conv_strides +(1,),\n",
    "                 padding = 'VALID')\n",
    "    convnet = tf.nn.bias_add(convnet, bias)\n",
    "    convnet = tf.nn.relu(convnet)\n",
    "    convnet = tf.nn.max_pool(convnet, \n",
    "                          ksize = (1,) + pool_ksize + (1,),\n",
    "                          strides = (1,) + pool_strides + (1,),\n",
    "                          padding = 'VALID')\n",
    "    \n",
    "    return convnet \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    tensor_shape = x_tensor.get_shape()\n",
    "    image_size = tensor_shape[1].value * tensor_shape[2].value * tensor_shape[3].value\n",
    "\n",
    "    return tf.reshape(x_tensor,[-1,image_size])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    tensor_shape = x_tensor.get_shape()\n",
    "    weight = tf.Variable(tf.truncated_normal([tensor_shape[1].value,num_outputs],\n",
    "                                             stddev=1/np.sqrt(tensor_shape[1].value)))\n",
    "    bias = tf.Variable(tf.zeros([num_outputs]))\n",
    "    return tf.nn.relu(tf.add(tf.matmul(x_tensor, weight), bias))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    tensor_shape = x_tensor.get_shape()\n",
    "    weight = tf.Variable(tf.truncated_normal([tensor_shape[1].value,num_outputs], \n",
    "                                             stddev=1/np.sqrt(tensor_shape[1].value)))\n",
    "    bias = tf.Variable(tf.zeros([num_outputs]))\n",
    "    return tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv = conv2d_maxpool(x, 32, (5,5), (2,2), (3,3), (1,1))\n",
    "    conv = tf.nn.dropout(conv, keep_prob)\n",
    "    conv = conv2d_maxpool(conv, 64, (3,3), (1,1), (2,2), (1,1))\n",
    "    conv = tf.nn.dropout(conv, keep_prob)\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    conv = flatten(conv)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    #conv = fully_conn(conv,60)\n",
    "    #conv = tf.nn.dropout(conv, keep_prob)    \n",
    "    conv = fully_conn(conv,200)  \n",
    "    conv = tf.nn.dropout(conv,keep_prob)  \n",
    "    conv = fully_conn(conv,100)  \n",
    "    conv = tf.nn.dropout(conv,keep_prob)  \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)    \n",
    "    conv = output(conv,10) \n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    return conv\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict= {\n",
    "            x: feature_batch,\n",
    "            y: label_batch,\n",
    "            keep_prob: keep_probability\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    t_loss = session.run(cost, feed_dict = {\n",
    "        x: feature_batch,\n",
    "        y: label_batch,\n",
    "        keep_prob: 1.\n",
    "    })\n",
    "    t_accu = session.run(accuracy, feed_dict = {\n",
    "        x: feature_batch,\n",
    "        y: label_batch,\n",
    "        keep_prob: 1.\n",
    "    })\n",
    "    v_loss = session.run(cost, feed_dict = {\n",
    "        x: valid_features,\n",
    "        y: valid_labels,\n",
    "        keep_prob: 1.\n",
    "    })\n",
    "    v_accu = session.run(accuracy, feed_dict = {\n",
    "        x: valid_features,\n",
    "        y: valid_labels,\n",
    "        keep_prob: 1.\n",
    "    })\n",
    "    print ('T_Loss: {:>10.4f} t_Accuracy: {:.6f} V_Loss: {:>10.4f} V_Accuracy: {:.6f}'.format(t_loss,\n",
    "                t_accu,v_loss,v_accu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "keep_probability = 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  T_Loss:     2.2235 t_Accuracy: 0.100000 V_Loss:     2.1698 V_Accuracy: 0.215400\n",
      "Epoch  2, CIFAR-10 Batch 1:  T_Loss:     2.0683 t_Accuracy: 0.225000 V_Loss:     1.8909 V_Accuracy: 0.338200\n",
      "Epoch  3, CIFAR-10 Batch 1:  T_Loss:     1.9407 t_Accuracy: 0.250000 V_Loss:     1.7401 V_Accuracy: 0.405000\n",
      "Epoch  4, CIFAR-10 Batch 1:  T_Loss:     1.8379 t_Accuracy: 0.325000 V_Loss:     1.6744 V_Accuracy: 0.433600\n",
      "Epoch  5, CIFAR-10 Batch 1:  T_Loss:     1.7623 t_Accuracy: 0.325000 V_Loss:     1.6041 V_Accuracy: 0.429400\n",
      "Epoch  6, CIFAR-10 Batch 1:  T_Loss:     1.8097 t_Accuracy: 0.375000 V_Loss:     1.5867 V_Accuracy: 0.439000\n",
      "Epoch  7, CIFAR-10 Batch 1:  T_Loss:     1.6400 t_Accuracy: 0.375000 V_Loss:     1.5476 V_Accuracy: 0.467400\n",
      "Epoch  8, CIFAR-10 Batch 1:  T_Loss:     1.5823 t_Accuracy: 0.425000 V_Loss:     1.4990 V_Accuracy: 0.477800\n",
      "Epoch  9, CIFAR-10 Batch 1:  T_Loss:     1.5434 t_Accuracy: 0.450000 V_Loss:     1.4578 V_Accuracy: 0.487600\n",
      "Epoch 10, CIFAR-10 Batch 1:  T_Loss:     1.5507 t_Accuracy: 0.500000 V_Loss:     1.4576 V_Accuracy: 0.486200\n",
      "Epoch 11, CIFAR-10 Batch 1:  T_Loss:     1.4376 t_Accuracy: 0.475000 V_Loss:     1.4157 V_Accuracy: 0.497000\n",
      "Epoch 12, CIFAR-10 Batch 1:  T_Loss:     1.4799 t_Accuracy: 0.525000 V_Loss:     1.4177 V_Accuracy: 0.505800\n",
      "Epoch 13, CIFAR-10 Batch 1:  T_Loss:     1.3988 t_Accuracy: 0.525000 V_Loss:     1.3935 V_Accuracy: 0.505000\n",
      "Epoch 14, CIFAR-10 Batch 1:  T_Loss:     1.3317 t_Accuracy: 0.450000 V_Loss:     1.3913 V_Accuracy: 0.507000\n",
      "Epoch 15, CIFAR-10 Batch 1:  T_Loss:     1.3652 t_Accuracy: 0.425000 V_Loss:     1.3899 V_Accuracy: 0.511200\n",
      "Epoch 16, CIFAR-10 Batch 1:  T_Loss:     1.2516 t_Accuracy: 0.550000 V_Loss:     1.3465 V_Accuracy: 0.526000\n",
      "Epoch 17, CIFAR-10 Batch 1:  T_Loss:     1.2767 t_Accuracy: 0.500000 V_Loss:     1.3554 V_Accuracy: 0.515000\n",
      "Epoch 18, CIFAR-10 Batch 1:  T_Loss:     1.2518 t_Accuracy: 0.525000 V_Loss:     1.3422 V_Accuracy: 0.527400\n",
      "Epoch 19, CIFAR-10 Batch 1:  T_Loss:     1.2447 t_Accuracy: 0.550000 V_Loss:     1.3466 V_Accuracy: 0.532800\n",
      "Epoch 20, CIFAR-10 Batch 1:  T_Loss:     1.2414 t_Accuracy: 0.550000 V_Loss:     1.3507 V_Accuracy: 0.522400\n",
      "Epoch 21, CIFAR-10 Batch 1:  T_Loss:     1.2538 t_Accuracy: 0.550000 V_Loss:     1.3466 V_Accuracy: 0.521800\n",
      "Epoch 22, CIFAR-10 Batch 1:  T_Loss:     1.2021 t_Accuracy: 0.625000 V_Loss:     1.3220 V_Accuracy: 0.531400\n",
      "Epoch 23, CIFAR-10 Batch 1:  T_Loss:     1.2150 t_Accuracy: 0.550000 V_Loss:     1.3606 V_Accuracy: 0.513800\n",
      "Epoch 24, CIFAR-10 Batch 1:  T_Loss:     1.1172 t_Accuracy: 0.600000 V_Loss:     1.2928 V_Accuracy: 0.546000\n",
      "Epoch 25, CIFAR-10 Batch 1:  T_Loss:     1.1074 t_Accuracy: 0.600000 V_Loss:     1.2819 V_Accuracy: 0.553800\n",
      "Epoch 26, CIFAR-10 Batch 1:  T_Loss:     1.1236 t_Accuracy: 0.625000 V_Loss:     1.2768 V_Accuracy: 0.548200\n",
      "Epoch 27, CIFAR-10 Batch 1:  T_Loss:     1.0578 t_Accuracy: 0.625000 V_Loss:     1.2646 V_Accuracy: 0.550400\n",
      "Epoch 28, CIFAR-10 Batch 1:  T_Loss:     1.0421 t_Accuracy: 0.675000 V_Loss:     1.2937 V_Accuracy: 0.542400\n",
      "Epoch 29, CIFAR-10 Batch 1:  T_Loss:     1.1472 t_Accuracy: 0.575000 V_Loss:     1.2925 V_Accuracy: 0.544400\n",
      "Epoch 30, CIFAR-10 Batch 1:  T_Loss:     1.0450 t_Accuracy: 0.675000 V_Loss:     1.2355 V_Accuracy: 0.565800\n",
      "Epoch 31, CIFAR-10 Batch 1:  T_Loss:     1.0263 t_Accuracy: 0.675000 V_Loss:     1.2654 V_Accuracy: 0.553200\n",
      "Epoch 32, CIFAR-10 Batch 1:  T_Loss:     1.0327 t_Accuracy: 0.600000 V_Loss:     1.2361 V_Accuracy: 0.566800\n",
      "Epoch 33, CIFAR-10 Batch 1:  T_Loss:     1.0121 t_Accuracy: 0.600000 V_Loss:     1.2516 V_Accuracy: 0.557200\n",
      "Epoch 34, CIFAR-10 Batch 1:  T_Loss:     0.9474 t_Accuracy: 0.650000 V_Loss:     1.2218 V_Accuracy: 0.578200\n",
      "Epoch 35, CIFAR-10 Batch 1:  T_Loss:     0.9899 t_Accuracy: 0.675000 V_Loss:     1.2517 V_Accuracy: 0.562400\n",
      "Epoch 36, CIFAR-10 Batch 1:  T_Loss:     0.9891 t_Accuracy: 0.700000 V_Loss:     1.2323 V_Accuracy: 0.569200\n",
      "Epoch 37, CIFAR-10 Batch 1:  T_Loss:     0.9916 t_Accuracy: 0.675000 V_Loss:     1.3226 V_Accuracy: 0.542800\n",
      "Epoch 38, CIFAR-10 Batch 1:  T_Loss:     0.9741 t_Accuracy: 0.625000 V_Loss:     1.2269 V_Accuracy: 0.568200\n",
      "Epoch 39, CIFAR-10 Batch 1:  T_Loss:     0.9020 t_Accuracy: 0.700000 V_Loss:     1.2143 V_Accuracy: 0.569600\n",
      "Epoch 40, CIFAR-10 Batch 1:  T_Loss:     0.9598 t_Accuracy: 0.625000 V_Loss:     1.2168 V_Accuracy: 0.573800\n",
      "Epoch 41, CIFAR-10 Batch 1:  T_Loss:     0.8897 t_Accuracy: 0.650000 V_Loss:     1.2093 V_Accuracy: 0.579600\n",
      "Epoch 42, CIFAR-10 Batch 1:  T_Loss:     0.9187 t_Accuracy: 0.600000 V_Loss:     1.2579 V_Accuracy: 0.562600\n",
      "Epoch 43, CIFAR-10 Batch 1:  T_Loss:     0.9282 t_Accuracy: 0.650000 V_Loss:     1.2376 V_Accuracy: 0.572400\n",
      "Epoch 44, CIFAR-10 Batch 1:  T_Loss:     0.9088 t_Accuracy: 0.725000 V_Loss:     1.2221 V_Accuracy: 0.573200\n",
      "Epoch 45, CIFAR-10 Batch 1:  T_Loss:     0.8332 t_Accuracy: 0.675000 V_Loss:     1.2141 V_Accuracy: 0.570000\n",
      "Epoch 46, CIFAR-10 Batch 1:  T_Loss:     0.8964 t_Accuracy: 0.650000 V_Loss:     1.2436 V_Accuracy: 0.565800\n",
      "Epoch 47, CIFAR-10 Batch 1:  T_Loss:     0.8335 t_Accuracy: 0.700000 V_Loss:     1.2168 V_Accuracy: 0.579200\n",
      "Epoch 48, CIFAR-10 Batch 1:  T_Loss:     0.8875 t_Accuracy: 0.700000 V_Loss:     1.2073 V_Accuracy: 0.577200\n",
      "Epoch 49, CIFAR-10 Batch 1:  T_Loss:     0.8106 t_Accuracy: 0.700000 V_Loss:     1.2036 V_Accuracy: 0.570600\n",
      "Epoch 50, CIFAR-10 Batch 1:  T_Loss:     0.8525 t_Accuracy: 0.725000 V_Loss:     1.2699 V_Accuracy: 0.550800\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  T_Loss:     2.1528 t_Accuracy: 0.200000 V_Loss:     2.0676 V_Accuracy: 0.297800\n",
      "Epoch  1, CIFAR-10 Batch 2:  T_Loss:     1.8965 t_Accuracy: 0.300000 V_Loss:     1.9036 V_Accuracy: 0.297400\n",
      "Epoch  1, CIFAR-10 Batch 3:  T_Loss:     1.4988 t_Accuracy: 0.600000 V_Loss:     1.6767 V_Accuracy: 0.401400\n",
      "Epoch  1, CIFAR-10 Batch 4:  T_Loss:     1.7021 t_Accuracy: 0.275000 V_Loss:     1.6269 V_Accuracy: 0.441200\n",
      "Epoch  1, CIFAR-10 Batch 5:  T_Loss:     1.6744 t_Accuracy: 0.500000 V_Loss:     1.6087 V_Accuracy: 0.444600\n",
      "Epoch  2, CIFAR-10 Batch 1:  T_Loss:     1.6548 t_Accuracy: 0.425000 V_Loss:     1.5375 V_Accuracy: 0.476200\n",
      "Epoch  2, CIFAR-10 Batch 2:  T_Loss:     1.6617 t_Accuracy: 0.400000 V_Loss:     1.5432 V_Accuracy: 0.464400\n",
      "Epoch  2, CIFAR-10 Batch 3:  T_Loss:     1.3685 t_Accuracy: 0.525000 V_Loss:     1.4892 V_Accuracy: 0.473800\n",
      "Epoch  2, CIFAR-10 Batch 4:  T_Loss:     1.5951 t_Accuracy: 0.350000 V_Loss:     1.5312 V_Accuracy: 0.476800\n",
      "Epoch  2, CIFAR-10 Batch 5:  T_Loss:     1.5530 t_Accuracy: 0.475000 V_Loss:     1.4419 V_Accuracy: 0.498800\n",
      "Epoch  3, CIFAR-10 Batch 1:  T_Loss:     1.5164 t_Accuracy: 0.500000 V_Loss:     1.4555 V_Accuracy: 0.508400\n",
      "Epoch  3, CIFAR-10 Batch 2:  T_Loss:     1.5600 t_Accuracy: 0.375000 V_Loss:     1.4534 V_Accuracy: 0.500000\n",
      "Epoch  3, CIFAR-10 Batch 3:  T_Loss:     1.3244 t_Accuracy: 0.575000 V_Loss:     1.4361 V_Accuracy: 0.499400\n",
      "Epoch  3, CIFAR-10 Batch 4:  T_Loss:     1.4557 t_Accuracy: 0.400000 V_Loss:     1.4036 V_Accuracy: 0.521800\n",
      "Epoch  3, CIFAR-10 Batch 5:  T_Loss:     1.5475 t_Accuracy: 0.500000 V_Loss:     1.4209 V_Accuracy: 0.511600\n",
      "Epoch  4, CIFAR-10 Batch 1:  T_Loss:     1.3927 t_Accuracy: 0.600000 V_Loss:     1.3837 V_Accuracy: 0.532600\n",
      "Epoch  4, CIFAR-10 Batch 2:  T_Loss:     1.4618 t_Accuracy: 0.425000 V_Loss:     1.3578 V_Accuracy: 0.535600\n",
      "Epoch  4, CIFAR-10 Batch 3:  T_Loss:     1.1553 t_Accuracy: 0.575000 V_Loss:     1.3548 V_Accuracy: 0.533200\n",
      "Epoch  4, CIFAR-10 Batch 4:  T_Loss:     1.4600 t_Accuracy: 0.350000 V_Loss:     1.3387 V_Accuracy: 0.532600\n",
      "Epoch  4, CIFAR-10 Batch 5:  T_Loss:     1.4550 t_Accuracy: 0.625000 V_Loss:     1.3608 V_Accuracy: 0.536000\n",
      "Epoch  5, CIFAR-10 Batch 1:  T_Loss:     1.3288 t_Accuracy: 0.525000 V_Loss:     1.3325 V_Accuracy: 0.552800\n",
      "Epoch  5, CIFAR-10 Batch 2:  T_Loss:     1.3881 t_Accuracy: 0.425000 V_Loss:     1.3111 V_Accuracy: 0.545400\n",
      "Epoch  5, CIFAR-10 Batch 3:  T_Loss:     1.1432 t_Accuracy: 0.600000 V_Loss:     1.3255 V_Accuracy: 0.529400\n",
      "Epoch  5, CIFAR-10 Batch 4:  T_Loss:     1.3199 t_Accuracy: 0.550000 V_Loss:     1.3576 V_Accuracy: 0.542200\n",
      "Epoch  5, CIFAR-10 Batch 5:  T_Loss:     1.3882 t_Accuracy: 0.525000 V_Loss:     1.3274 V_Accuracy: 0.552600\n",
      "Epoch  6, CIFAR-10 Batch 1:  T_Loss:     1.2411 t_Accuracy: 0.575000 V_Loss:     1.2801 V_Accuracy: 0.564200\n",
      "Epoch  6, CIFAR-10 Batch 2:  T_Loss:     1.2932 t_Accuracy: 0.525000 V_Loss:     1.2743 V_Accuracy: 0.562000\n",
      "Epoch  6, CIFAR-10 Batch 3:  T_Loss:     1.1408 t_Accuracy: 0.550000 V_Loss:     1.2552 V_Accuracy: 0.560800\n",
      "Epoch  6, CIFAR-10 Batch 4:  T_Loss:     1.2753 t_Accuracy: 0.575000 V_Loss:     1.2484 V_Accuracy: 0.573400\n",
      "Epoch  6, CIFAR-10 Batch 5:  T_Loss:     1.3158 t_Accuracy: 0.500000 V_Loss:     1.3051 V_Accuracy: 0.555800\n",
      "Epoch  7, CIFAR-10 Batch 1:  T_Loss:     1.3154 t_Accuracy: 0.500000 V_Loss:     1.2470 V_Accuracy: 0.578600\n",
      "Epoch  7, CIFAR-10 Batch 2:  T_Loss:     1.2336 t_Accuracy: 0.575000 V_Loss:     1.2542 V_Accuracy: 0.574400\n",
      "Epoch  7, CIFAR-10 Batch 3:  T_Loss:     1.0385 t_Accuracy: 0.675000 V_Loss:     1.2206 V_Accuracy: 0.575600\n",
      "Epoch  7, CIFAR-10 Batch 4:  T_Loss:     1.2335 t_Accuracy: 0.525000 V_Loss:     1.2364 V_Accuracy: 0.579000\n",
      "Epoch  7, CIFAR-10 Batch 5:  T_Loss:     1.2566 t_Accuracy: 0.575000 V_Loss:     1.2257 V_Accuracy: 0.581600\n",
      "Epoch  8, CIFAR-10 Batch 1:  T_Loss:     1.2071 t_Accuracy: 0.600000 V_Loss:     1.2222 V_Accuracy: 0.584400\n",
      "Epoch  8, CIFAR-10 Batch 2:  T_Loss:     1.1673 t_Accuracy: 0.550000 V_Loss:     1.2059 V_Accuracy: 0.593800\n",
      "Epoch  8, CIFAR-10 Batch 3:  T_Loss:     1.0077 t_Accuracy: 0.625000 V_Loss:     1.1792 V_Accuracy: 0.585600\n",
      "Epoch  8, CIFAR-10 Batch 4:  T_Loss:     1.2076 t_Accuracy: 0.425000 V_Loss:     1.2218 V_Accuracy: 0.588000\n",
      "Epoch  8, CIFAR-10 Batch 5:  T_Loss:     1.2841 t_Accuracy: 0.525000 V_Loss:     1.2571 V_Accuracy: 0.567600\n",
      "Epoch  9, CIFAR-10 Batch 1:  T_Loss:     1.2127 t_Accuracy: 0.525000 V_Loss:     1.2045 V_Accuracy: 0.587800\n",
      "Epoch  9, CIFAR-10 Batch 2:  T_Loss:     1.1526 t_Accuracy: 0.600000 V_Loss:     1.1797 V_Accuracy: 0.597000\n",
      "Epoch  9, CIFAR-10 Batch 3:  T_Loss:     0.9797 t_Accuracy: 0.625000 V_Loss:     1.1707 V_Accuracy: 0.594600\n",
      "Epoch  9, CIFAR-10 Batch 4:  T_Loss:     1.1419 t_Accuracy: 0.500000 V_Loss:     1.1754 V_Accuracy: 0.603600\n",
      "Epoch  9, CIFAR-10 Batch 5:  T_Loss:     1.2117 t_Accuracy: 0.550000 V_Loss:     1.1988 V_Accuracy: 0.593600\n",
      "Epoch 10, CIFAR-10 Batch 1:  T_Loss:     1.2805 t_Accuracy: 0.500000 V_Loss:     1.1703 V_Accuracy: 0.597200\n",
      "Epoch 10, CIFAR-10 Batch 2:  T_Loss:     1.1989 t_Accuracy: 0.550000 V_Loss:     1.1722 V_Accuracy: 0.592800\n",
      "Epoch 10, CIFAR-10 Batch 3:  T_Loss:     0.9776 t_Accuracy: 0.700000 V_Loss:     1.1645 V_Accuracy: 0.585000\n",
      "Epoch 10, CIFAR-10 Batch 4:  T_Loss:     1.1562 t_Accuracy: 0.500000 V_Loss:     1.1637 V_Accuracy: 0.602200\n",
      "Epoch 10, CIFAR-10 Batch 5:  T_Loss:     1.1894 t_Accuracy: 0.525000 V_Loss:     1.1992 V_Accuracy: 0.579200\n",
      "Epoch 11, CIFAR-10 Batch 1:  T_Loss:     1.1764 t_Accuracy: 0.575000 V_Loss:     1.1356 V_Accuracy: 0.614800\n",
      "Epoch 11, CIFAR-10 Batch 2:  T_Loss:     1.1166 t_Accuracy: 0.575000 V_Loss:     1.1369 V_Accuracy: 0.616200\n",
      "Epoch 11, CIFAR-10 Batch 3:  T_Loss:     0.9037 t_Accuracy: 0.700000 V_Loss:     1.1278 V_Accuracy: 0.609400\n",
      "Epoch 11, CIFAR-10 Batch 4:  T_Loss:     1.1112 t_Accuracy: 0.600000 V_Loss:     1.1590 V_Accuracy: 0.605600\n",
      "Epoch 11, CIFAR-10 Batch 5:  T_Loss:     1.1639 t_Accuracy: 0.550000 V_Loss:     1.1461 V_Accuracy: 0.601400\n",
      "Epoch 12, CIFAR-10 Batch 1:  T_Loss:     1.1601 t_Accuracy: 0.500000 V_Loss:     1.1294 V_Accuracy: 0.616600\n",
      "Epoch 12, CIFAR-10 Batch 2:  T_Loss:     1.0691 t_Accuracy: 0.575000 V_Loss:     1.1329 V_Accuracy: 0.624400\n",
      "Epoch 12, CIFAR-10 Batch 3:  T_Loss:     0.9302 t_Accuracy: 0.625000 V_Loss:     1.1806 V_Accuracy: 0.581400\n",
      "Epoch 12, CIFAR-10 Batch 4:  T_Loss:     1.1301 t_Accuracy: 0.600000 V_Loss:     1.1496 V_Accuracy: 0.615400\n",
      "Epoch 12, CIFAR-10 Batch 5:  T_Loss:     1.1282 t_Accuracy: 0.550000 V_Loss:     1.1156 V_Accuracy: 0.618600\n",
      "Epoch 13, CIFAR-10 Batch 1:  T_Loss:     1.1842 t_Accuracy: 0.500000 V_Loss:     1.1589 V_Accuracy: 0.600800\n",
      "Epoch 13, CIFAR-10 Batch 2:  T_Loss:     1.1764 t_Accuracy: 0.575000 V_Loss:     1.1182 V_Accuracy: 0.622600\n",
      "Epoch 13, CIFAR-10 Batch 3:  T_Loss:     0.8643 t_Accuracy: 0.725000 V_Loss:     1.1073 V_Accuracy: 0.619000\n",
      "Epoch 13, CIFAR-10 Batch 4:  T_Loss:     1.1739 t_Accuracy: 0.525000 V_Loss:     1.1337 V_Accuracy: 0.619800\n",
      "Epoch 13, CIFAR-10 Batch 5:  T_Loss:     1.1682 t_Accuracy: 0.525000 V_Loss:     1.1420 V_Accuracy: 0.602200\n",
      "Epoch 14, CIFAR-10 Batch 1:  T_Loss:     1.1491 t_Accuracy: 0.550000 V_Loss:     1.1457 V_Accuracy: 0.606200\n",
      "Epoch 14, CIFAR-10 Batch 2:  T_Loss:     1.1076 t_Accuracy: 0.550000 V_Loss:     1.1134 V_Accuracy: 0.626000\n",
      "Epoch 14, CIFAR-10 Batch 3:  T_Loss:     0.8466 t_Accuracy: 0.700000 V_Loss:     1.1050 V_Accuracy: 0.605000\n",
      "Epoch 14, CIFAR-10 Batch 4:  T_Loss:     1.0632 t_Accuracy: 0.600000 V_Loss:     1.1074 V_Accuracy: 0.628000\n",
      "Epoch 14, CIFAR-10 Batch 5:  T_Loss:     1.0571 t_Accuracy: 0.600000 V_Loss:     1.1638 V_Accuracy: 0.593600\n",
      "Epoch 15, CIFAR-10 Batch 1:  T_Loss:     1.1095 t_Accuracy: 0.525000 V_Loss:     1.0993 V_Accuracy: 0.624800\n",
      "Epoch 15, CIFAR-10 Batch 2:  T_Loss:     1.0435 t_Accuracy: 0.650000 V_Loss:     1.0776 V_Accuracy: 0.626600\n",
      "Epoch 15, CIFAR-10 Batch 3:  T_Loss:     0.7773 t_Accuracy: 0.750000 V_Loss:     1.0613 V_Accuracy: 0.634600\n",
      "Epoch 15, CIFAR-10 Batch 4:  T_Loss:     1.0343 t_Accuracy: 0.575000 V_Loss:     1.1125 V_Accuracy: 0.632000\n",
      "Epoch 15, CIFAR-10 Batch 5:  T_Loss:     1.1059 t_Accuracy: 0.525000 V_Loss:     1.1055 V_Accuracy: 0.624800\n",
      "Epoch 16, CIFAR-10 Batch 1:  T_Loss:     1.0981 t_Accuracy: 0.575000 V_Loss:     1.0871 V_Accuracy: 0.624400\n",
      "Epoch 16, CIFAR-10 Batch 2:  T_Loss:     1.0328 t_Accuracy: 0.550000 V_Loss:     1.1147 V_Accuracy: 0.618200\n",
      "Epoch 16, CIFAR-10 Batch 3:  T_Loss:     0.8148 t_Accuracy: 0.700000 V_Loss:     1.0522 V_Accuracy: 0.639400\n",
      "Epoch 16, CIFAR-10 Batch 4:  T_Loss:     1.0197 t_Accuracy: 0.500000 V_Loss:     1.0675 V_Accuracy: 0.637400\n",
      "Epoch 16, CIFAR-10 Batch 5:  T_Loss:     1.1068 t_Accuracy: 0.575000 V_Loss:     1.1243 V_Accuracy: 0.616400\n",
      "Epoch 17, CIFAR-10 Batch 1:  T_Loss:     1.1361 t_Accuracy: 0.550000 V_Loss:     1.1141 V_Accuracy: 0.615800\n",
      "Epoch 17, CIFAR-10 Batch 2:  T_Loss:     1.0136 t_Accuracy: 0.575000 V_Loss:     1.0973 V_Accuracy: 0.629400\n",
      "Epoch 17, CIFAR-10 Batch 3:  T_Loss:     0.8268 t_Accuracy: 0.675000 V_Loss:     1.0655 V_Accuracy: 0.633000\n",
      "Epoch 17, CIFAR-10 Batch 4:  T_Loss:     1.0410 t_Accuracy: 0.525000 V_Loss:     1.0883 V_Accuracy: 0.630800\n",
      "Epoch 17, CIFAR-10 Batch 5:  T_Loss:     1.0187 t_Accuracy: 0.650000 V_Loss:     1.0787 V_Accuracy: 0.625400\n",
      "Epoch 18, CIFAR-10 Batch 1:  T_Loss:     1.0889 t_Accuracy: 0.575000 V_Loss:     1.0915 V_Accuracy: 0.626000\n",
      "Epoch 18, CIFAR-10 Batch 2:  T_Loss:     0.9361 t_Accuracy: 0.625000 V_Loss:     1.0605 V_Accuracy: 0.634000\n",
      "Epoch 18, CIFAR-10 Batch 3:  T_Loss:     0.7440 t_Accuracy: 0.675000 V_Loss:     1.0507 V_Accuracy: 0.635600\n",
      "Epoch 18, CIFAR-10 Batch 4:  T_Loss:     1.0416 t_Accuracy: 0.575000 V_Loss:     1.0907 V_Accuracy: 0.631200\n",
      "Epoch 18, CIFAR-10 Batch 5:  T_Loss:     0.9667 t_Accuracy: 0.625000 V_Loss:     1.0567 V_Accuracy: 0.646400\n",
      "Epoch 19, CIFAR-10 Batch 1:  T_Loss:     1.1198 t_Accuracy: 0.575000 V_Loss:     1.0513 V_Accuracy: 0.640000\n",
      "Epoch 19, CIFAR-10 Batch 2:  T_Loss:     1.0386 t_Accuracy: 0.575000 V_Loss:     1.0606 V_Accuracy: 0.631800\n",
      "Epoch 19, CIFAR-10 Batch 3:  T_Loss:     0.7319 t_Accuracy: 0.775000 V_Loss:     1.0457 V_Accuracy: 0.631600\n",
      "Epoch 19, CIFAR-10 Batch 4:  T_Loss:     0.9779 t_Accuracy: 0.675000 V_Loss:     1.0698 V_Accuracy: 0.638000\n",
      "Epoch 19, CIFAR-10 Batch 5:  T_Loss:     1.0044 t_Accuracy: 0.625000 V_Loss:     1.0685 V_Accuracy: 0.638200\n",
      "Epoch 20, CIFAR-10 Batch 1:  T_Loss:     1.1096 t_Accuracy: 0.475000 V_Loss:     1.0689 V_Accuracy: 0.636600\n",
      "Epoch 20, CIFAR-10 Batch 2:  T_Loss:     0.9658 t_Accuracy: 0.675000 V_Loss:     1.0595 V_Accuracy: 0.640400\n",
      "Epoch 20, CIFAR-10 Batch 3:  T_Loss:     0.7516 t_Accuracy: 0.825000 V_Loss:     1.0467 V_Accuracy: 0.634600\n",
      "Epoch 20, CIFAR-10 Batch 4:  T_Loss:     1.0093 t_Accuracy: 0.600000 V_Loss:     1.0516 V_Accuracy: 0.646800\n",
      "Epoch 20, CIFAR-10 Batch 5:  T_Loss:     1.0307 t_Accuracy: 0.600000 V_Loss:     1.0550 V_Accuracy: 0.641400\n",
      "Epoch 21, CIFAR-10 Batch 1:  T_Loss:     1.0425 t_Accuracy: 0.550000 V_Loss:     1.0483 V_Accuracy: 0.640600\n",
      "Epoch 21, CIFAR-10 Batch 2:  T_Loss:     0.9336 t_Accuracy: 0.625000 V_Loss:     1.0470 V_Accuracy: 0.646800\n",
      "Epoch 21, CIFAR-10 Batch 3:  T_Loss:     0.7200 t_Accuracy: 0.775000 V_Loss:     1.0380 V_Accuracy: 0.651000\n",
      "Epoch 21, CIFAR-10 Batch 4:  T_Loss:     0.9979 t_Accuracy: 0.650000 V_Loss:     1.0463 V_Accuracy: 0.644800\n",
      "Epoch 21, CIFAR-10 Batch 5:  T_Loss:     0.9980 t_Accuracy: 0.625000 V_Loss:     1.0396 V_Accuracy: 0.647400\n",
      "Epoch 22, CIFAR-10 Batch 1:  T_Loss:     1.1065 t_Accuracy: 0.650000 V_Loss:     1.0631 V_Accuracy: 0.643000\n",
      "Epoch 22, CIFAR-10 Batch 2:  T_Loss:     0.9726 t_Accuracy: 0.600000 V_Loss:     1.0395 V_Accuracy: 0.646000\n",
      "Epoch 22, CIFAR-10 Batch 3:  T_Loss:     0.8495 t_Accuracy: 0.700000 V_Loss:     1.0454 V_Accuracy: 0.643000\n",
      "Epoch 22, CIFAR-10 Batch 4:  T_Loss:     0.9709 t_Accuracy: 0.675000 V_Loss:     1.0648 V_Accuracy: 0.631600\n",
      "Epoch 22, CIFAR-10 Batch 5:  T_Loss:     0.9507 t_Accuracy: 0.650000 V_Loss:     1.0391 V_Accuracy: 0.660400\n",
      "Epoch 23, CIFAR-10 Batch 1:  T_Loss:     1.0873 t_Accuracy: 0.575000 V_Loss:     1.0495 V_Accuracy: 0.643800\n",
      "Epoch 23, CIFAR-10 Batch 2:  T_Loss:     0.9463 t_Accuracy: 0.575000 V_Loss:     1.0146 V_Accuracy: 0.660200\n",
      "Epoch 23, CIFAR-10 Batch 3:  T_Loss:     0.7408 t_Accuracy: 0.800000 V_Loss:     1.0340 V_Accuracy: 0.638200\n",
      "Epoch 23, CIFAR-10 Batch 4:  T_Loss:     0.9549 t_Accuracy: 0.550000 V_Loss:     1.0276 V_Accuracy: 0.647800\n",
      "Epoch 23, CIFAR-10 Batch 5:  T_Loss:     0.9111 t_Accuracy: 0.675000 V_Loss:     1.0405 V_Accuracy: 0.650600\n",
      "Epoch 24, CIFAR-10 Batch 1:  T_Loss:     1.0581 t_Accuracy: 0.525000 V_Loss:     1.0219 V_Accuracy: 0.653600\n",
      "Epoch 24, CIFAR-10 Batch 2:  T_Loss:     0.9549 t_Accuracy: 0.650000 V_Loss:     1.0212 V_Accuracy: 0.643200\n",
      "Epoch 24, CIFAR-10 Batch 3:  T_Loss:     0.7346 t_Accuracy: 0.725000 V_Loss:     1.0300 V_Accuracy: 0.644800\n",
      "Epoch 24, CIFAR-10 Batch 4:  T_Loss:     0.9703 t_Accuracy: 0.575000 V_Loss:     1.0532 V_Accuracy: 0.637200\n",
      "Epoch 24, CIFAR-10 Batch 5:  T_Loss:     0.9640 t_Accuracy: 0.625000 V_Loss:     1.0165 V_Accuracy: 0.661400\n",
      "Epoch 25, CIFAR-10 Batch 1:  T_Loss:     1.0748 t_Accuracy: 0.625000 V_Loss:     1.0328 V_Accuracy: 0.647800\n",
      "Epoch 25, CIFAR-10 Batch 2:  T_Loss:     0.9825 t_Accuracy: 0.675000 V_Loss:     1.0659 V_Accuracy: 0.639400\n",
      "Epoch 25, CIFAR-10 Batch 3:  T_Loss:     0.7128 t_Accuracy: 0.825000 V_Loss:     1.0246 V_Accuracy: 0.649200\n",
      "Epoch 25, CIFAR-10 Batch 4:  T_Loss:     0.8964 t_Accuracy: 0.550000 V_Loss:     1.0097 V_Accuracy: 0.658200\n",
      "Epoch 25, CIFAR-10 Batch 5:  T_Loss:     0.9006 t_Accuracy: 0.700000 V_Loss:     1.0430 V_Accuracy: 0.645000\n",
      "Epoch 26, CIFAR-10 Batch 1:  T_Loss:     0.9264 t_Accuracy: 0.700000 V_Loss:     1.0189 V_Accuracy: 0.657200\n",
      "Epoch 26, CIFAR-10 Batch 2:  T_Loss:     0.9222 t_Accuracy: 0.650000 V_Loss:     1.0249 V_Accuracy: 0.649000\n",
      "Epoch 26, CIFAR-10 Batch 3:  T_Loss:     0.7326 t_Accuracy: 0.850000 V_Loss:     1.0139 V_Accuracy: 0.649800\n",
      "Epoch 26, CIFAR-10 Batch 4:  T_Loss:     0.9920 t_Accuracy: 0.600000 V_Loss:     1.0350 V_Accuracy: 0.650800\n",
      "Epoch 26, CIFAR-10 Batch 5:  T_Loss:     0.8884 t_Accuracy: 0.675000 V_Loss:     1.0236 V_Accuracy: 0.647600\n",
      "Epoch 27, CIFAR-10 Batch 1:  T_Loss:     1.0789 t_Accuracy: 0.700000 V_Loss:     1.0290 V_Accuracy: 0.646200\n",
      "Epoch 27, CIFAR-10 Batch 2:  T_Loss:     0.9222 t_Accuracy: 0.650000 V_Loss:     1.0119 V_Accuracy: 0.658800\n",
      "Epoch 27, CIFAR-10 Batch 3:  T_Loss:     0.7404 t_Accuracy: 0.775000 V_Loss:     1.0136 V_Accuracy: 0.650800\n",
      "Epoch 27, CIFAR-10 Batch 4:  T_Loss:     0.9175 t_Accuracy: 0.625000 V_Loss:     1.0122 V_Accuracy: 0.661400\n",
      "Epoch 27, CIFAR-10 Batch 5:  T_Loss:     0.9330 t_Accuracy: 0.725000 V_Loss:     1.0439 V_Accuracy: 0.654000\n",
      "Epoch 28, CIFAR-10 Batch 1:  T_Loss:     0.9876 t_Accuracy: 0.600000 V_Loss:     0.9965 V_Accuracy: 0.660600\n",
      "Epoch 28, CIFAR-10 Batch 2:  T_Loss:     0.8666 t_Accuracy: 0.600000 V_Loss:     1.0074 V_Accuracy: 0.661000\n",
      "Epoch 28, CIFAR-10 Batch 3:  T_Loss:     0.6826 t_Accuracy: 0.825000 V_Loss:     1.0267 V_Accuracy: 0.653400\n",
      "Epoch 28, CIFAR-10 Batch 4:  T_Loss:     0.9233 t_Accuracy: 0.675000 V_Loss:     1.0147 V_Accuracy: 0.651600\n",
      "Epoch 28, CIFAR-10 Batch 5:  T_Loss:     0.8125 t_Accuracy: 0.650000 V_Loss:     1.0170 V_Accuracy: 0.646400\n",
      "Epoch 29, CIFAR-10 Batch 1:  T_Loss:     1.0596 t_Accuracy: 0.575000 V_Loss:     1.0423 V_Accuracy: 0.635800\n",
      "Epoch 29, CIFAR-10 Batch 2:  T_Loss:     1.0126 t_Accuracy: 0.675000 V_Loss:     1.0143 V_Accuracy: 0.652000\n",
      "Epoch 29, CIFAR-10 Batch 3:  T_Loss:     0.7227 t_Accuracy: 0.750000 V_Loss:     1.0145 V_Accuracy: 0.651200\n",
      "Epoch 29, CIFAR-10 Batch 4:  T_Loss:     0.9197 t_Accuracy: 0.650000 V_Loss:     0.9974 V_Accuracy: 0.665000\n",
      "Epoch 29, CIFAR-10 Batch 5:  T_Loss:     0.7783 t_Accuracy: 0.725000 V_Loss:     1.0057 V_Accuracy: 0.651000\n",
      "Epoch 30, CIFAR-10 Batch 1:  T_Loss:     1.0188 t_Accuracy: 0.750000 V_Loss:     0.9876 V_Accuracy: 0.662000\n",
      "Epoch 30, CIFAR-10 Batch 2:  T_Loss:     0.8806 t_Accuracy: 0.650000 V_Loss:     1.0058 V_Accuracy: 0.657200\n",
      "Epoch 30, CIFAR-10 Batch 3:  T_Loss:     0.7065 t_Accuracy: 0.825000 V_Loss:     1.0160 V_Accuracy: 0.662600\n",
      "Epoch 30, CIFAR-10 Batch 4:  T_Loss:     0.8618 t_Accuracy: 0.725000 V_Loss:     1.0137 V_Accuracy: 0.660800\n",
      "Epoch 30, CIFAR-10 Batch 5:  T_Loss:     0.7819 t_Accuracy: 0.700000 V_Loss:     0.9759 V_Accuracy: 0.673200\n",
      "Epoch 31, CIFAR-10 Batch 1:  T_Loss:     1.0229 t_Accuracy: 0.600000 V_Loss:     1.0090 V_Accuracy: 0.648600\n",
      "Epoch 31, CIFAR-10 Batch 2:  T_Loss:     0.8863 t_Accuracy: 0.675000 V_Loss:     0.9957 V_Accuracy: 0.656200\n",
      "Epoch 31, CIFAR-10 Batch 3:  T_Loss:     0.6375 t_Accuracy: 0.750000 V_Loss:     0.9875 V_Accuracy: 0.662400\n",
      "Epoch 31, CIFAR-10 Batch 4:  T_Loss:     0.8660 t_Accuracy: 0.625000 V_Loss:     1.0022 V_Accuracy: 0.660200\n",
      "Epoch 31, CIFAR-10 Batch 5:  T_Loss:     0.8975 t_Accuracy: 0.675000 V_Loss:     1.0024 V_Accuracy: 0.657000\n",
      "Epoch 32, CIFAR-10 Batch 1:  T_Loss:     1.0045 t_Accuracy: 0.600000 V_Loss:     0.9952 V_Accuracy: 0.659600\n",
      "Epoch 32, CIFAR-10 Batch 2:  T_Loss:     0.8465 t_Accuracy: 0.625000 V_Loss:     0.9815 V_Accuracy: 0.676800\n",
      "Epoch 32, CIFAR-10 Batch 3:  T_Loss:     0.6455 t_Accuracy: 0.800000 V_Loss:     0.9749 V_Accuracy: 0.666200\n",
      "Epoch 32, CIFAR-10 Batch 4:  T_Loss:     0.8178 t_Accuracy: 0.700000 V_Loss:     0.9938 V_Accuracy: 0.669000\n",
      "Epoch 32, CIFAR-10 Batch 5:  T_Loss:     0.8293 t_Accuracy: 0.650000 V_Loss:     0.9978 V_Accuracy: 0.666200\n",
      "Epoch 33, CIFAR-10 Batch 1:  T_Loss:     1.0149 t_Accuracy: 0.550000 V_Loss:     1.0050 V_Accuracy: 0.655200\n",
      "Epoch 33, CIFAR-10 Batch 2:  T_Loss:     0.8099 t_Accuracy: 0.650000 V_Loss:     0.9832 V_Accuracy: 0.656000\n",
      "Epoch 33, CIFAR-10 Batch 3:  T_Loss:     0.6653 t_Accuracy: 0.800000 V_Loss:     0.9785 V_Accuracy: 0.668200\n",
      "Epoch 33, CIFAR-10 Batch 4:  T_Loss:     0.8445 t_Accuracy: 0.675000 V_Loss:     0.9930 V_Accuracy: 0.664800\n",
      "Epoch 33, CIFAR-10 Batch 5:  T_Loss:     0.8048 t_Accuracy: 0.650000 V_Loss:     0.9931 V_Accuracy: 0.666600\n",
      "Epoch 34, CIFAR-10 Batch 1:  T_Loss:     1.0203 t_Accuracy: 0.575000 V_Loss:     1.0306 V_Accuracy: 0.637000\n",
      "Epoch 34, CIFAR-10 Batch 2:  T_Loss:     0.8376 t_Accuracy: 0.725000 V_Loss:     0.9879 V_Accuracy: 0.657600\n",
      "Epoch 34, CIFAR-10 Batch 3:  T_Loss:     0.6036 t_Accuracy: 0.850000 V_Loss:     0.9685 V_Accuracy: 0.674000\n",
      "Epoch 34, CIFAR-10 Batch 4:  T_Loss:     0.8638 t_Accuracy: 0.700000 V_Loss:     0.9871 V_Accuracy: 0.666400\n",
      "Epoch 34, CIFAR-10 Batch 5:  T_Loss:     0.9153 t_Accuracy: 0.675000 V_Loss:     1.0283 V_Accuracy: 0.656200\n",
      "Epoch 35, CIFAR-10 Batch 1:  T_Loss:     0.9122 t_Accuracy: 0.675000 V_Loss:     0.9812 V_Accuracy: 0.667800\n",
      "Epoch 35, CIFAR-10 Batch 2:  T_Loss:     0.8323 t_Accuracy: 0.725000 V_Loss:     0.9652 V_Accuracy: 0.669400\n",
      "Epoch 35, CIFAR-10 Batch 3:  T_Loss:     0.5656 t_Accuracy: 0.875000 V_Loss:     0.9649 V_Accuracy: 0.675400\n",
      "Epoch 35, CIFAR-10 Batch 4:  T_Loss:     0.8182 t_Accuracy: 0.700000 V_Loss:     0.9716 V_Accuracy: 0.678800\n",
      "Epoch 35, CIFAR-10 Batch 5:  T_Loss:     0.8140 t_Accuracy: 0.625000 V_Loss:     0.9751 V_Accuracy: 0.675000\n",
      "Epoch 36, CIFAR-10 Batch 1:  T_Loss:     0.9486 t_Accuracy: 0.650000 V_Loss:     0.9823 V_Accuracy: 0.666600\n",
      "Epoch 36, CIFAR-10 Batch 2:  T_Loss:     0.8719 t_Accuracy: 0.625000 V_Loss:     0.9949 V_Accuracy: 0.657000\n",
      "Epoch 36, CIFAR-10 Batch 3:  T_Loss:     0.6139 t_Accuracy: 0.875000 V_Loss:     0.9805 V_Accuracy: 0.659200\n",
      "Epoch 36, CIFAR-10 Batch 4:  T_Loss:     0.7924 t_Accuracy: 0.675000 V_Loss:     0.9712 V_Accuracy: 0.672600\n",
      "Epoch 36, CIFAR-10 Batch 5:  T_Loss:     0.8003 t_Accuracy: 0.700000 V_Loss:     0.9861 V_Accuracy: 0.667000\n",
      "Epoch 37, CIFAR-10 Batch 1:  T_Loss:     0.9005 t_Accuracy: 0.650000 V_Loss:     0.9878 V_Accuracy: 0.667600\n",
      "Epoch 37, CIFAR-10 Batch 2:  T_Loss:     0.8309 t_Accuracy: 0.700000 V_Loss:     0.9723 V_Accuracy: 0.666000\n",
      "Epoch 37, CIFAR-10 Batch 3:  T_Loss:     0.6755 t_Accuracy: 0.825000 V_Loss:     0.9976 V_Accuracy: 0.660200\n",
      "Epoch 37, CIFAR-10 Batch 4:  T_Loss:     0.8109 t_Accuracy: 0.775000 V_Loss:     0.9697 V_Accuracy: 0.673600\n",
      "Epoch 37, CIFAR-10 Batch 5:  T_Loss:     0.7722 t_Accuracy: 0.725000 V_Loss:     0.9736 V_Accuracy: 0.672600\n",
      "Epoch 38, CIFAR-10 Batch 1:  T_Loss:     1.0080 t_Accuracy: 0.650000 V_Loss:     1.0325 V_Accuracy: 0.645000\n",
      "Epoch 38, CIFAR-10 Batch 2:  T_Loss:     0.8506 t_Accuracy: 0.675000 V_Loss:     0.9786 V_Accuracy: 0.654200\n",
      "Epoch 38, CIFAR-10 Batch 3:  T_Loss:     0.6228 t_Accuracy: 0.825000 V_Loss:     0.9608 V_Accuracy: 0.672200\n",
      "Epoch 38, CIFAR-10 Batch 4:  T_Loss:     0.8603 t_Accuracy: 0.650000 V_Loss:     1.0058 V_Accuracy: 0.654000\n",
      "Epoch 38, CIFAR-10 Batch 5:  T_Loss:     0.7870 t_Accuracy: 0.725000 V_Loss:     0.9734 V_Accuracy: 0.664800\n",
      "Epoch 39, CIFAR-10 Batch 1:  T_Loss:     0.9055 t_Accuracy: 0.700000 V_Loss:     0.9773 V_Accuracy: 0.673200\n",
      "Epoch 39, CIFAR-10 Batch 2:  T_Loss:     0.8168 t_Accuracy: 0.675000 V_Loss:     0.9759 V_Accuracy: 0.664400\n",
      "Epoch 39, CIFAR-10 Batch 3:  T_Loss:     0.6314 t_Accuracy: 0.800000 V_Loss:     0.9546 V_Accuracy: 0.675800\n",
      "Epoch 39, CIFAR-10 Batch 4:  T_Loss:     0.7788 t_Accuracy: 0.750000 V_Loss:     0.9827 V_Accuracy: 0.667000\n",
      "Epoch 39, CIFAR-10 Batch 5:  T_Loss:     0.7195 t_Accuracy: 0.775000 V_Loss:     0.9551 V_Accuracy: 0.676800\n",
      "Epoch 40, CIFAR-10 Batch 1:  T_Loss:     0.8981 t_Accuracy: 0.625000 V_Loss:     0.9718 V_Accuracy: 0.669400\n",
      "Epoch 40, CIFAR-10 Batch 2:  T_Loss:     0.7774 t_Accuracy: 0.700000 V_Loss:     1.0081 V_Accuracy: 0.655000\n",
      "Epoch 40, CIFAR-10 Batch 3:  T_Loss:     0.6514 t_Accuracy: 0.850000 V_Loss:     0.9646 V_Accuracy: 0.669000\n",
      "Epoch 40, CIFAR-10 Batch 4:  T_Loss:     0.8198 t_Accuracy: 0.700000 V_Loss:     0.9517 V_Accuracy: 0.681200\n",
      "Epoch 40, CIFAR-10 Batch 5:  T_Loss:     0.7961 t_Accuracy: 0.700000 V_Loss:     0.9611 V_Accuracy: 0.674400\n",
      "Epoch 41, CIFAR-10 Batch 1:  T_Loss:     0.9487 t_Accuracy: 0.650000 V_Loss:     0.9778 V_Accuracy: 0.656400\n",
      "Epoch 41, CIFAR-10 Batch 2:  T_Loss:     0.8282 t_Accuracy: 0.750000 V_Loss:     0.9804 V_Accuracy: 0.673600\n",
      "Epoch 41, CIFAR-10 Batch 3:  T_Loss:     0.6296 t_Accuracy: 0.825000 V_Loss:     0.9503 V_Accuracy: 0.672200\n",
      "Epoch 41, CIFAR-10 Batch 4:  T_Loss:     0.8554 t_Accuracy: 0.700000 V_Loss:     1.0123 V_Accuracy: 0.653400\n",
      "Epoch 41, CIFAR-10 Batch 5:  T_Loss:     0.7953 t_Accuracy: 0.625000 V_Loss:     0.9815 V_Accuracy: 0.667000\n",
      "Epoch 42, CIFAR-10 Batch 1:  T_Loss:     0.9445 t_Accuracy: 0.675000 V_Loss:     0.9708 V_Accuracy: 0.665200\n",
      "Epoch 42, CIFAR-10 Batch 2:  T_Loss:     0.8307 t_Accuracy: 0.675000 V_Loss:     0.9581 V_Accuracy: 0.671800\n",
      "Epoch 42, CIFAR-10 Batch 3:  T_Loss:     0.6935 t_Accuracy: 0.725000 V_Loss:     0.9958 V_Accuracy: 0.651600\n",
      "Epoch 42, CIFAR-10 Batch 4:  T_Loss:     0.8900 t_Accuracy: 0.625000 V_Loss:     0.9746 V_Accuracy: 0.669800\n",
      "Epoch 42, CIFAR-10 Batch 5:  T_Loss:     0.7560 t_Accuracy: 0.850000 V_Loss:     0.9631 V_Accuracy: 0.673600\n",
      "Epoch 43, CIFAR-10 Batch 1:  T_Loss:     0.9347 t_Accuracy: 0.650000 V_Loss:     0.9852 V_Accuracy: 0.663000\n",
      "Epoch 43, CIFAR-10 Batch 2:  T_Loss:     0.7317 t_Accuracy: 0.725000 V_Loss:     0.9627 V_Accuracy: 0.665600\n",
      "Epoch 43, CIFAR-10 Batch 3:  T_Loss:     0.6130 t_Accuracy: 0.850000 V_Loss:     0.9819 V_Accuracy: 0.659600\n",
      "Epoch 43, CIFAR-10 Batch 4:  T_Loss:     0.7041 t_Accuracy: 0.800000 V_Loss:     0.9452 V_Accuracy: 0.685600\n",
      "Epoch 43, CIFAR-10 Batch 5:  T_Loss:     0.7637 t_Accuracy: 0.725000 V_Loss:     0.9990 V_Accuracy: 0.666800\n",
      "Epoch 44, CIFAR-10 Batch 1:  T_Loss:     0.8790 t_Accuracy: 0.700000 V_Loss:     0.9561 V_Accuracy: 0.673000\n",
      "Epoch 44, CIFAR-10 Batch 2:  T_Loss:     0.8296 t_Accuracy: 0.725000 V_Loss:     0.9705 V_Accuracy: 0.668200\n",
      "Epoch 44, CIFAR-10 Batch 3:  T_Loss:     0.6203 t_Accuracy: 0.875000 V_Loss:     0.9561 V_Accuracy: 0.673600\n",
      "Epoch 44, CIFAR-10 Batch 4:  T_Loss:     0.7955 t_Accuracy: 0.675000 V_Loss:     0.9939 V_Accuracy: 0.668000\n",
      "Epoch 44, CIFAR-10 Batch 5:  T_Loss:     0.7095 t_Accuracy: 0.775000 V_Loss:     0.9525 V_Accuracy: 0.681400\n",
      "Epoch 45, CIFAR-10 Batch 1:  T_Loss:     0.9097 t_Accuracy: 0.750000 V_Loss:     0.9444 V_Accuracy: 0.674600\n",
      "Epoch 45, CIFAR-10 Batch 2:  T_Loss:     0.8572 t_Accuracy: 0.650000 V_Loss:     0.9986 V_Accuracy: 0.651800\n",
      "Epoch 45, CIFAR-10 Batch 3:  T_Loss:     0.6296 t_Accuracy: 0.800000 V_Loss:     0.9589 V_Accuracy: 0.671000\n",
      "Epoch 45, CIFAR-10 Batch 4:  T_Loss:     0.8021 t_Accuracy: 0.700000 V_Loss:     0.9846 V_Accuracy: 0.657800\n",
      "Epoch 45, CIFAR-10 Batch 5:  T_Loss:     0.7367 t_Accuracy: 0.700000 V_Loss:     0.9627 V_Accuracy: 0.669400\n",
      "Epoch 46, CIFAR-10 Batch 1:  T_Loss:     0.9136 t_Accuracy: 0.725000 V_Loss:     0.9936 V_Accuracy: 0.658400\n",
      "Epoch 46, CIFAR-10 Batch 2:  T_Loss:     0.8229 t_Accuracy: 0.675000 V_Loss:     0.9717 V_Accuracy: 0.665600\n",
      "Epoch 46, CIFAR-10 Batch 3:  T_Loss:     0.5969 t_Accuracy: 0.850000 V_Loss:     0.9511 V_Accuracy: 0.675000\n",
      "Epoch 46, CIFAR-10 Batch 4:  T_Loss:     0.7756 t_Accuracy: 0.750000 V_Loss:     0.9595 V_Accuracy: 0.674200\n",
      "Epoch 46, CIFAR-10 Batch 5:  T_Loss:     0.7011 t_Accuracy: 0.750000 V_Loss:     0.9554 V_Accuracy: 0.670000\n",
      "Epoch 47, CIFAR-10 Batch 1:  T_Loss:     0.8438 t_Accuracy: 0.675000 V_Loss:     0.9680 V_Accuracy: 0.667000\n",
      "Epoch 47, CIFAR-10 Batch 2:  T_Loss:     0.8035 t_Accuracy: 0.750000 V_Loss:     0.9648 V_Accuracy: 0.663600\n",
      "Epoch 47, CIFAR-10 Batch 3:  T_Loss:     0.6274 t_Accuracy: 0.850000 V_Loss:     0.9571 V_Accuracy: 0.672800\n",
      "Epoch 47, CIFAR-10 Batch 4:  T_Loss:     0.7235 t_Accuracy: 0.800000 V_Loss:     0.9584 V_Accuracy: 0.670600\n",
      "Epoch 47, CIFAR-10 Batch 5:  T_Loss:     0.7616 t_Accuracy: 0.700000 V_Loss:     0.9512 V_Accuracy: 0.675800\n",
      "Epoch 48, CIFAR-10 Batch 1:  T_Loss:     0.8999 t_Accuracy: 0.725000 V_Loss:     0.9806 V_Accuracy: 0.659800\n",
      "Epoch 48, CIFAR-10 Batch 2:  T_Loss:     0.8572 t_Accuracy: 0.700000 V_Loss:     0.9985 V_Accuracy: 0.647200\n",
      "Epoch 48, CIFAR-10 Batch 3:  T_Loss:     0.6175 t_Accuracy: 0.900000 V_Loss:     0.9342 V_Accuracy: 0.678000\n",
      "Epoch 48, CIFAR-10 Batch 4:  T_Loss:     0.8298 t_Accuracy: 0.700000 V_Loss:     0.9565 V_Accuracy: 0.673000\n",
      "Epoch 48, CIFAR-10 Batch 5:  T_Loss:     0.7541 t_Accuracy: 0.725000 V_Loss:     0.9676 V_Accuracy: 0.670400\n",
      "Epoch 49, CIFAR-10 Batch 1:  T_Loss:     0.8347 t_Accuracy: 0.750000 V_Loss:     0.9469 V_Accuracy: 0.681600\n",
      "Epoch 49, CIFAR-10 Batch 2:  T_Loss:     0.8271 t_Accuracy: 0.675000 V_Loss:     0.9621 V_Accuracy: 0.669200\n",
      "Epoch 49, CIFAR-10 Batch 3:  T_Loss:     0.6403 t_Accuracy: 0.800000 V_Loss:     0.9573 V_Accuracy: 0.668400\n",
      "Epoch 49, CIFAR-10 Batch 4:  T_Loss:     0.7045 t_Accuracy: 0.825000 V_Loss:     0.9481 V_Accuracy: 0.675600\n",
      "Epoch 49, CIFAR-10 Batch 5:  T_Loss:     0.7670 t_Accuracy: 0.750000 V_Loss:     0.9624 V_Accuracy: 0.669200\n",
      "Epoch 50, CIFAR-10 Batch 1:  T_Loss:     0.8871 t_Accuracy: 0.700000 V_Loss:     0.9611 V_Accuracy: 0.664000\n",
      "Epoch 50, CIFAR-10 Batch 2:  T_Loss:     0.7739 t_Accuracy: 0.675000 V_Loss:     0.9420 V_Accuracy: 0.673400\n",
      "Epoch 50, CIFAR-10 Batch 3:  T_Loss:     0.5944 t_Accuracy: 0.850000 V_Loss:     0.9391 V_Accuracy: 0.679800\n",
      "Epoch 50, CIFAR-10 Batch 4:  T_Loss:     0.7354 t_Accuracy: 0.700000 V_Loss:     0.9535 V_Accuracy: 0.668000\n",
      "Epoch 50, CIFAR-10 Batch 5:  T_Loss:     0.7316 t_Accuracy: 0.675000 V_Loss:     0.9444 V_Accuracy: 0.683600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.6753582802547771\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff51c1ca358>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. That's because there are many more techniques that can be applied to your model and we recemmond that once you are done with this project, you explore!\n",
    "\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
